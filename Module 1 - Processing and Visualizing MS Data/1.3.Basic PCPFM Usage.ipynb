{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic PCPFM Usage\n",
    "\n",
    "The Python-Centric Pipeline for Metabolomics is an Asari-based ecosystem for computational metabolomics data processing. Here we will perform a basic PCPFM analysis that is analagous to the standalone Asari processing done in notebook 1.1. By using the pipeline for running Asari, we can do more complex stuff later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets start by installing the pipeline\n",
    "\n",
    "!pip install pcpfm\n",
    "\n",
    "# Patching\n",
    "!pip install isocor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata CSV Generation\n",
    "\n",
    "The current pipeline implementation works best with a metadata CSV that details the file name, its location, and the \"type\" of sample for every sample you wish to analyze. Lets create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to generate a very basic CSV file to tell the pipeline where the mzML files are located.\n",
    "# future versions of the pipeline will not require this step.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "metadata_dicts = []\n",
    "for x in os.listdir(\"../../Datasets/MT02Dataset/\"):\n",
    "  if x.endswith(\".mzML\"):\n",
    "    metadata_dicts.append({\n",
    "        \"File Name\": x.rstrip(\".mzML\"), # this is to tell the pcpfm what to call the sample\n",
    "        \"Sample Type\": \"Unknown\", # this field specifies what sort of acquisition this is, needed for advanced usage.\n",
    "        \"Filepath\": os.path.join(os.path.abspath(\"../../Datasets/MT02Dataset/\"), x) # this is to tell pcpfm where the mzML is located\n",
    "    })\n",
    "    print(x)\n",
    "metadata_df = pd.DataFrame(metadata_dicts)\n",
    "metadata_df.to_csv(\"metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual PCPFM procesisng\n",
    "\n",
    "PCPFM is a python package but it can be ran like another program from the commmand line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example:\n",
    "\n",
    "!pcpfm\n",
    "\n",
    "# you should see an error message and some instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets start working with the pipeline. The assemble command creates the experiment object\n",
    "# that stores all intermediates.\n",
    "\n",
    "!pcpfm assemble -o . -j pcpfm_tutorial_basic -s ./metadata.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a list of the output directories in the pipeline directory\n",
    "os.listdir(\"./pcpfm_tutorial_basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can run asari within the pipeline, this will automatically infer the ionization type of the samples.\n",
    "# all acquisitions must be collected in the same ionization mode!\n",
    "\n",
    "!pcpfm asari -i pcpfm_tutorial_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets examine the feature table as we did previously\n",
    "# here we can load the JSON file within the experiment directory to get the feature table path\n",
    "import json\n",
    "\n",
    "exp = json.load(open(\"./pcpfm_tutorial_basic/experiment.json\"))\n",
    "exp[\"feature_tables\"]\n",
    "\n",
    "# see we have two feature tables: 'preferred' and 'full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should have the same feature table as in the asari standalone example\n",
    "\n",
    "ft = pd.read_csv(exp[\"feature_tables\"][\"preferred\"], sep=\"\\t\")\n",
    "print(\"Num Samples = \", ft.shape[1]-11)\n",
    "print(\"Num Features = \", ft.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
