{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "# Data processing With Asari\n",
    "\n",
    "Multiple tools exist for processing mass spectra into feature tables. \n",
    "Asari is a recent open-source tool, described in:\n",
    "\n",
    "Li, et al, 2023. Trackable and scalable LC-MS metabolomics data processing using asari. Nature Communications, 14(1), p.4113. (https://www.nature.com/articles/s41467-023-39889-1)\n",
    "\n",
    "In this notebook we will use Asari from the CLI (via the notebook) to analyze a representative LC-MS dataset and visualize some of the data. \n",
    "\n",
    "The notebook (and Colab) is used for teaching. In production environment, one can run Asari as commandline and in a pipeline, scripts etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1fjoqvFizQL4orI_Jlb9lTfpCIv_Hd8DT?authuser=1\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets verify all needed packages are installed\n",
    "\n",
    "!pip3 install asari-metabolomics\n",
    "\n",
    "import requests, zipfile, io, os\n",
    "\n",
    "os.makedirs(\"./Datasets\", exist_ok=True)\n",
    "\n",
    "datasets = [\n",
    "    \"https://github.com/shuzhao-li-lab/data/raw/main/data/MT02Dataset.zip\",\n",
    "]\n",
    "\n",
    "for dataset in datasets:\n",
    "    r = requests.get(dataset)\n",
    "    if dataset.endswith(\".zip\"):\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        z.extractall(\"./Datasets/\")\n",
    "    else:\n",
    "        with open(\"./Datasets/\" + os.path.basename(dataset), 'bw+') as out_fh:\n",
    "            out_fh.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# now lets run asari on our test dataset. \n",
    "# the arguments to asari do the following:\n",
    "#   -i specifies the input directory\n",
    "#   -o specifies where to save the output\n",
    "#   -m indicates the ionization mode, either pos or neg\n",
    "#   -j is the name of the results directory so we can find it later\n",
    "#   --pickle true and --database_mode ondisk are optional parameters that will keep intermediate data structures for visualization alter.\n",
    "\n",
    "!asari process -i ./Datasets/MT02Dataset/ -m pos -j MT02_results --pickle true --database_mode ondisk\n",
    "\n",
    "# After you exeucte this block, you should see the output from asari."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Asari Outputs\n",
    "\n",
    "After running the previous block, you have successfully pre-processed the LC-MS data into a feature table and other outputs. Lets look at these results more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the outputs from the asari run\n",
    "\n",
    "import os \n",
    "asari_subdir = None\n",
    "for x in os.listdir(\"./\"):\n",
    "    if x.startswith(\"Results_MT02_results\"): # here we are using the name specified earlier\n",
    "        asari_subdir = os.path.join(os.path.abspath(\"./\"), x)\n",
    "preferred_table = os.path.join(asari_subdir, \"preferred_Feature_table.tsv\") # this is the high-quality feature table\n",
    "annotation_table = os.path.join(asari_subdir, \"Feature_annotation.tsv\") # this is annotations generated by asari based on the serum subset of the HMDBv4   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining the Feature Table\n",
    "\n",
    "A feature is an aligned peak across all the samples in the experiment. How the feature intensity is calculated is shown in the next notebook.\n",
    "\n",
    "More features is not always better as many features are low quality (poor quantification, poor peak shape etc.). The recommended feature table to use in Asari is therefore the preferred table, which is a summary of high quality features only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets count how many samples and how many features were returned.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# use pandas to read the feature table, note that it is .tsv, so we need to specify the delimiter character.\n",
    "ft = pd.read_csv(preferred_table, sep=\"\\t\")\n",
    "\n",
    "# the first 11 columns are properties of the features, the remaining columns are per-sample intensities\n",
    "print(\"Num_Samples = \", ft.shape[1]-11)\n",
    "\n",
    "# the first row is the header, but the rest represent a feature.\n",
    "print(\"Num_Features = \", ft.shape[0]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this shows the top rows of the feature table\n",
    "ft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the preferred feature table contains only high-quality features. we can see this by looking at the distributions of cSelectivity, goodness of fit, and SNR.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "ax1.hist(ft['cSelectivity'])\n",
    "ax1.set_title(\"cSelectivity\")\n",
    "ax2.hist(ft['goodness_fitting'])\n",
    "ax2.set_title(\"goodness_fitting\")\n",
    "ax3.hist(np.log2(ft['snr']))\n",
    "ax3.set_title(\"log2 snr\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# we will examine more plotting in Module 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at a feature from the table\n",
    "\n",
    "plt.bar(ft.columns[11:], ft[ft['id_number'] == \"F1\"][ft.columns[11:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at the default annotation returned by Asari\n",
    "\n",
    "annots = pd.read_csv(annotation_table, sep=\"\\t\")\n",
    "annots.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Summary\n",
    "\n",
    "Now you can process data using Asari and explore its outputs. With some modification, you can reuse this notebook on your own data.\n",
    "\n",
    "Next we will run Asari as part of a pipeline rather than by itself. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
