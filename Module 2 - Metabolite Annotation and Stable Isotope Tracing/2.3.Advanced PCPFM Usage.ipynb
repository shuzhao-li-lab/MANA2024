{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced usage of the PCPFM pipeline\n",
    "\n",
    "In this module, we will extend the previous analyses we did with the PCPFM by adding annotation and basic data processing such as normalization. \n",
    "\n",
    "Annotation is assigned from multiple sources and with different confidence levels. MS2 examples are included here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/shuzhao-li-lab/MANA2024/blob/main/Module%202%20-%20Metabolite%20Annotation%20and%20Stable%20Isotope%20Tracing/2.3.Advanced%20PCPFM%20Usage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages \n",
    "\n",
    "!pip3 install pcpfm isocor\n",
    "\n",
    "import requests, zipfile, io, os\n",
    "\n",
    "os.makedirs(\"./Datasets\", exist_ok=True)\n",
    "\n",
    "datasets = [\n",
    "    \"https://github.com/shuzhao-li-lab/asari_pcpfm_tutorials/releases/download/v.data_release_0.0.1-alpha/MT01.zip\",\n",
    "    \"https://github.com/shuzhao-li-lab/asari_pcpfm_tutorials/releases/download/v.data_release_0.0.1-alpha/MT01_MS2.zip\",\n",
    "]\n",
    "\n",
    "for dataset in datasets:\n",
    "    r = requests.get(dataset)\n",
    "    if dataset.endswith(\".zip\"):\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        z.extractall(\"./Datasets/\")\n",
    "    else:\n",
    "        with open(\"./Datasets/\" + os.path.basename(dataset), 'bw+') as out_fh:\n",
    "            out_fh.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets make the metadata csv\n",
    "# here we will use a slightly different dataset that includes an MS2 acquisition, a corrupted mzML file, and some blanks.\n",
    "# we will do annotation on this dataset and some QAQC\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "metadata_dicts = []\n",
    "for x in os.listdir(\"./Datasets/MT01\"):\n",
    "  if x.endswith(\".mzML\"):\n",
    "    metadata_dicts.append({\n",
    "        \"File Name\": x.rstrip(\".mzML\"),\n",
    "        \"Sample Type\": \"Unknown\" if \"Blank\" not in x else \"Blank\",\n",
    "        \"Filepath\": os.path.join(os.path.abspath(\"./Datasets/MT01\"), x),\n",
    "        \"Method\": \"Unknown\"\n",
    "    })\n",
    "metadata_df = pd.DataFrame(metadata_dicts)\n",
    "metadata_df.to_csv(\"adv_metadata.csv\")\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pre-Processing\n",
    "\n",
    "This section is essentially the basic PCPFM notebook from module 1, we will add to it later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets assemble the experiment object\n",
    "\n",
    "!pcpfm assemble -o . -j pcpfm_tutorial_advanced -s ./adv_metadata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now run asari\n",
    "# note that the corrupted mzML file is simply skipped during asari, effectively dropping it from the analysis.\n",
    "\n",
    "!pcpfm asari -i ./pcpfm_tutorial_advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets examine the feature table as we did previously\n",
    "# here we can load the JSON file within the experiment directory to get the feature table path\n",
    "import json\n",
    "\n",
    "exp = json.load(open(\"./pcpfm_tutorial_advanced/experiment.json\"))\n",
    "exp[\"feature_tables\"]\n",
    "\n",
    "# see we have two feature tables: 'preferred' and 'full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = pd.read_csv(exp[\"feature_tables\"][\"preferred\"], sep=\"\\t\")\n",
    "print(\"Num Samples = \", ft.shape[1]-11)\n",
    "print(\"Num Features = \", ft.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New PCPFM Functionality\n",
    "\n",
    "Lets introduce some new functions. Lets start with additions to pre-processing include some QA/QC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets generate the pdf report to see the QA/QC plots. (This will take some time...)\n",
    "\n",
    "!pcpfm report -i ./pcpfm_tutorial_advanced/ --color_by='[\"Sample Type\"]' --text_by='[\"File Name\"]'\n",
    "\n",
    "# you can open the report by clicking on the files to the left, then navigating to the path below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the report, see the z-score count on page 10. Clearly the MSplate10 sample has many more features.\n",
    "# This sample is not plasma, so we should drop it before normalizing all the other plasma samples.\n",
    "# similarly we should not include blanks in the normalization.\n",
    "\n",
    "# This command will drop the blanks from the preferred table and save it to a new table named \"preferred_no_blanks\"\n",
    "\n",
    "!pcpfm drop_samples --table_moniker preferred --new_moniker preferred_no_blanks --drop_value Blank --drop_field \"Sample Type\" -i ./pcpfm_tutorial_advanced/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets drop the MSplate sample by name\n",
    "# no output will be generated here confirming a sample was dropped\n",
    "\n",
    "!pcpfm drop_samples --table_moniker preferred_no_blanks --new_moniker cleaned_preferred --drop_name MSplate10_pgpB_b1278_G5_platePN_rep2_HEAT_GEIII_0-829_1125 -i ./pcpfm_tutorial_advanced/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can normalize the samples based on TIC of common features.\n",
    "# This is now a reasonable normalization procedure as all samples are now similar matrices\n",
    "\n",
    "!pcpfm normalize --table_moniker cleaned_preferred --new_moniker normalized -i ./pcpfm_tutorial_advanced/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation in the PCPFM\n",
    "\n",
    "Now we introduce the annotation portion of the PCPFM starting with construction of empirical compounds, download of annotation databases and then MS1 and MS2 based annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could do more to process the feature table, but lets move on to empirical compounds\n",
    "# asari builds a default list of empirical compounds when it is ran, but we can build\n",
    "# a new set in the pipeline. This is useful when you want to customize the rules for\n",
    "# empCpd construction.\n",
    "\n",
    "# by default, this will use the ionization mode determined by the pipeline, common adducts\n",
    "# for that mode, and isotopes up to m+13C3\n",
    "\n",
    "!pcpfm build_empCpds -i ./pcpfm_tutorial_advanced/ -tm full -em full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have empirical compounds we can start to annotate them.\n",
    "# due to license restrictions, you have to download the HMDB, lipid MAPS, and MoNA\n",
    "# using the pipeline, it does not come pre-installed.\n",
    "\n",
    "!pcpfm download_extras --accept_licenses True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have multiple empirical compounds:\n",
    "\n",
    "exp = json.load(open(\"./pcpfm_tutorial_advanced/experiment.json\"))\n",
    "exp[\"empCpds\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets show an example of MS2 annotations:\n",
    "# first we need to line up MS2 acquisitions from another experiment / acquisition to features in this experiment\n",
    "# by default this uses a 30 second rt tolerance and a 5 ppm m/z tolerance. The 5 ppm tolerance is effectively 10 ppm due to mass error in \n",
    "# the features + mass error in the precursor ions. \n",
    "# the ms2 dir can be a file or a directory of files\n",
    "\n",
    "!pcpfm map_ms2 -i ./pcpfm_tutorial_advanced/ -em full -nm MS2_mapped --ms2_dir=../../Datasets/ID_01.mzML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets annotate those mapping. This will use the MoNA orbitrap LC-MS/MS database for \n",
    "# the ionization mode determined by the pipeline.\n",
    "# ignore the warnings, these are due to an underlying library\n",
    "\n",
    "!pcpfm l2_annotate -i ./pcpfm_tutorial_advanced -em MS2_mapped -nm MoNA_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the HMDB and LMSD downloaded, we can now generate Level4, m/z only, annotations to the empCpds as follows\n",
    "\n",
    "!pcpfm l4_annotate -i ./pcpfm_tutorial_advanced/ -em MoNA_annotated -nm MoNA_HMDB_LMSD_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, if you are comfortable with JSON, you have completed the processing.\n",
    "# But if you would prefer to have tables for use with other tools, we can generate these with the following command:\n",
    "\n",
    "!pcpfm generate_output -i ./pcpfm_tutorial_advanced/ -em MoNA_HMDB_LMSD_annotated -tm cleaned_preferred \n",
    "\n",
    "# This will map the MoNA_HMDB_LMSD_annotated empCpd annotations back to the cleaned_preferred feature table we created earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets explore the outputs\n",
    "\n",
    "The PCFPM organizes the outputs from each standalone tool and organizes them in the output subdirectory. Lets checkout what our run from the PCPFM generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the outputs will be located in the output subdirectory:\n",
    "\n",
    "print(os.listdir(\"./pcpfm_tutorial_advanced/output/\"))\n",
    "\n",
    "# this includes the feature table you specified: 'cleaned_preferred_Feature_table.tsv'\n",
    "# the empCpd file: 'MoNA_HMDB_LMSD_annotated_empCpds.json'\n",
    "# the sample_annotation_table: 'sample_annot_table.tsv', this records sample metadata,\n",
    "# the feature annotation table: 'annotation_table.tsv', this is a record of the annotations\n",
    "# and the experiment.json: 'experiment.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at the annotations\n",
    "# this table summarizes the annotations for the features, what level they are, and associated information.\n",
    "\n",
    "pd.read_csv(\"./pcpfm_tutorial_advanced/output/annotation_table.tsv\", sep=\"\\t\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at the annotations but only MS2\n",
    "# we can do this with a simple filter and removing any annotation without as MS2 score\n",
    "\n",
    "at = pd.read_csv(\"./pcpfm_tutorial_advanced/output/annotation_table.tsv\", sep=\"\\t\")\n",
    "at.dropna(subset=[\"msms_score\"], inplace=True) \n",
    "at.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at the feature table\n",
    "# based the preferred table from Asari, here the cleaned version we created in the pipeline has been blanked masked and normalized. \n",
    "\n",
    "pd.read_csv(\"./pcpfm_tutorial_advanced/output/cleaned_preferred_Feature_table.tsv\", sep=\"\\t\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the sample annotation table, essentially this stores all provided metadata on the samples.\n",
    "# future versions of the pipeline will use this table for other uses as well\n",
    "\n",
    "pd.read_csv(\"./pcpfm_tutorial_advanced/output/sample_annot_table.tsv\", sep=\"\\t\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Summary\n",
    "\n",
    "We have expanded on our earlier pipeline notebook to include annotation and basic qa/qc data processing. Many workflows can be built using the pipeline, for examples, please see the PCPFM repository. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
